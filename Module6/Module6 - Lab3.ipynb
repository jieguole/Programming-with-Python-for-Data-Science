{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module6- Lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load up the /Module6/Datasets/parkinsons.data data set into a variable X, being sure to drop the name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/parkinsons.data')\n",
    "print(X.head(10))\n",
    "X.drop('name', axis = 1, inplace = True)\n",
    "print(X.isnull().sum())\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splice out the status column into a variable y and delete it from X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = X.status\n",
    "X.drop(labels=['status'], axis=1, inplace= True)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a train/test split. 30% test group size, with a random_state equal to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SVC classifier. Don't specify any parameters, just leave everything as default. Fit it against your training data and then score your testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That accuracy was just too low to be useful. We need to get it up. One way you could go about doing that would be to manually try a bunch of combinations of C, and gamma values for your rbf kernel. But that could literally take forever. Also, you might unknowingly skip a pair of values that would have resulted in a very good accuracy.\n",
    "Instead, lets get the computer to do what computers do best. Program a naive, best-parameter search by creating nested for-loops. The outer for-loop should iterate a variable C from 0.05 to 2, using 0.05 unit increments. The inner for-loop should increment a variable gamma from 0.001 to 0.1, using 0.001 unit increments. As you know, Python ranges won't allow for float intervals, so you'll have to do some research on NumPy ARanges, if you don't already know how to use them.\n",
    "Since the goal is to find the parameters that result in the model having the best accuracy score, you'll need a best_score = 0 variable that you initialize outside of the for-loops. Inside the inner for-loop, create an SVC model and pass in the C and gamma parameters its class constructor. Train and score the model appropriately. If the current best_score is less than the model's score, update the best_score being sure to print it out, along with the C and gamma values that resulted in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_score = 0 \n",
    "for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "    for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "        model = SVC(C = i, gamma = j)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_C = model.C\n",
    "            best_gamma = model.gamma\n",
    "print(\"The highest score obtained:\", best_score)\n",
    "print(\"C value:\", best_C)\n",
    "print(\"gamma value:\", best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second. Pull open the dataset's label file from: https://archive.ics.uci.edu/ml/datasets/Parkinsons\n",
    "Look at the units on those columns: Hz, %, Abs, dB, etc. What happened to transforming your data? With all of those units interacting with one another, some pre-processing is surely in order.\n",
    "Right after you preform the train/test split but before you train your model, inject SciKit-Learn's pre-processing code. Unless you have a good idea which one is going to work best, you're going to have to try the various pre-processors one at a time, checking to see if they improve your predictive accuracy.\n",
    "Experiment with Normalizer(), MaxAbsScaler(), MinMaxScaler(), KernelCenterer(), and StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/parkinsons.data')\n",
    "X.drop('name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = X.status\n",
    "X.drop(labels=['status'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#T = preprocessing.Normalizer().fit_transform(X)\n",
    "#T = preprocessing.MaxAbsScaler().fit_transform(X)\n",
    "#T = preprocessing.MinMaxScaler().fit_transform(X)\n",
    "#T = preprocessing.KernelCenterer().fit_transform(X)\n",
    "T = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(T, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_score = 0 \n",
    "for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "    for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "        model = SVC(C = i, gamma = j)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_C = model.C\n",
    "            best_gamma = model.gamma\n",
    "print(\"The highest score obtained:\", best_score)\n",
    "print(\"C value:\", best_C)\n",
    "print(\"gamma value:\", best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score keeps creeping upwards. Let's have one more go at it. Remember how in a previous lab we discovered that SVM's are a bit sensitive to outliers and that just throwing all of our unfiltered, dirty or noisy data at it, particularly in high-dimensionality space, can actually cause the accuracy score to suffer?\n",
    "Well, let's try to get rid of some useless features. Immediately after you do the pre-processing, run PCA on your dataset. The original dataset has 22 columns and 1 label column. So try experimenting with PCA n_component values between 4 and 14. Are you able to get a better accuracy?\n",
    "If you are not, then forget about PCA entirely. However if you are able to get a higher score, then be sure keep that accuracy score in mind, and comment out all the PCA code for now.\n",
    "In the same spot, run Isomap on the data. Manually experiment with every inclusive combination of n_neighbors between 2 and 5, and n_components between 4 and 6. Are you able to get a better accuracy?\n",
    "If you are not, then forget about isomap entirely. However if you are able to get a higher score, then be sure keep that figure in mind.\n",
    "If either PCA or Isomap helped you out, then uncomment out the appropriate transformation code so that you have the highest accuracy possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/parkinsons.data')\n",
    "X.drop('name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X.status\n",
    "X.drop(labels=['status'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "T = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current highest score is: 0.796610169492 with 4 PCA components and  0.05 C and  0.001 gamma\n",
      "The current highest score is: 0.813559322034 with 4 PCA components and  0.15 C and  0.029 gamma\n",
      "The current highest score is: 0.830508474576 with 4 PCA components and  0.15 C and  0.032 gamma\n",
      "The current highest score is: 0.847457627119 with 4 PCA components and  0.15 C and  0.036 gamma\n",
      "The current highest score is: 0.864406779661 with 4 PCA components and  0.2 C and  0.024 gamma\n",
      "The current highest score is: 0.881355932203 with 4 PCA components and  0.2 C and  0.034 gamma\n",
      "The current highest score is: 0.898305084746 with 4 PCA components and  0.55 C and  0.094 gamma\n",
      "The current highest score is: 0.915254237288 with 5 PCA components and  0.45 C and  0.065 gamma\n",
      "The current highest score is: 0.932203389831 with 7 PCA components and  1.75 C and  0.099 gamma\n",
      "The highest score obtained: 0.932203389831\n",
      "PCA n_components: 7\n",
      "C value: 1.75\n",
      "gamma value: 0.099\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "for m in range(4, 15):\n",
    "    pca = PCA(n_components = m)\n",
    "    X_pca = pca.fit_transform(T)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size = 0.3, random_state = 7)        \n",
    "            \n",
    "    for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "        for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "            model = SVC(C = i, gamma = j)\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_C = model.C\n",
    "                best_gamma = model.gamma\n",
    "                best_pca_components = pca.n_components        \n",
    "                print(\"The current highest score is:\", best_score, \"with\", best_pca_components, \"PCA components and \", best_C, \"C and \", best_gamma, \"gamma\")\n",
    "                \n",
    "print(\"The highest score obtained:\", best_score)\n",
    "print(\"PCA n_components:\", best_pca_components)\n",
    "print(\"C value:\", best_C)\n",
    "print(\"gamma value:\", best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/parkinsons.data')\n",
    "X.drop('name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X.status\n",
    "X.drop(labels=['status'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "T = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current highest score is: 0.796610169492 with 2 neighbors and  4 components and 0.05 C and  0.001 gamma\n",
      "The current highest score is: 0.813559322034 with 2 neighbors and  4 components and 0.1 C and  0.007 gamma\n",
      "The current highest score is: 0.830508474576 with 2 neighbors and  4 components and 0.1 C and  0.008 gamma\n",
      "The current highest score is: 0.847457627119 with 2 neighbors and  4 components and 0.1 C and  0.01 gamma\n",
      "The current highest score is: 0.864406779661 with 2 neighbors and  4 components and 0.15 C and  0.008 gamma\n",
      "The current highest score is: 0.881355932203 with 2 neighbors and  4 components and 0.45 C and  0.009 gamma\n",
      "The current highest score is: 0.898305084746 with 2 neighbors and  4 components and 0.45 C and  0.011 gamma\n",
      "The current highest score is: 0.915254237288 with 2 neighbors and  4 components and 0.5 C and  0.014 gamma\n",
      "The current highest score is: 0.932203389831 with 2 neighbors and  4 components and 0.65 C and  0.036 gamma\n",
      "The current highest score is: 0.949152542373 with 2 neighbors and  4 components and 1.05 C and  0.032 gamma\n",
      "The current highest score is: 0.966101694915 with 2 neighbors and  4 components and 1.7 C and  0.06 gamma\n",
      "The highest score obtained: 0.966101694915\n",
      "isomap n_neighbors: 2\n",
      "isomap n_components: 4\n",
      "C value: 1.7\n",
      "gamma value: 0.06\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "for k in range(2, 6):\n",
    "    for l in range(4, 7):\n",
    "        iso = Isomap(n_neighbors = k, n_components = l)\n",
    "        X_iso = iso.fit_transform(T)                \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_iso, y, test_size = 0.3, random_state = 7)        \n",
    "        \n",
    "\n",
    "        for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "            for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "                model = SVC(C = i, gamma = j)\n",
    "                model.fit(X_train, y_train)\n",
    "                score = model.score(X_test, y_test)\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_C = model.C\n",
    "                    best_gamma = model.gamma\n",
    "                    best_n_neighbors = iso.n_neighbors\n",
    "                    best_n_components = iso.n_components\n",
    "                    print(\"The current highest score is:\", best_score, \"with\", best_n_neighbors, \n",
    "                          \"neighbors and\", best_n_components, \"components and\", best_C, \"C and \", best_gamma, \"gamma\")\n",
    "\n",
    "                       \n",
    "print(\"The highest score obtained:\", best_score)\n",
    "print(\"isomap n_neighbors:\", best_n_neighbors)\n",
    "print(\"isomap n_components:\", best_n_components)\n",
    "print(\"C value:\", best_C)\n",
    "print(\"gamma value:\", best_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
